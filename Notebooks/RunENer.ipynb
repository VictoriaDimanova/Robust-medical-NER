{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMrE6sWpHjz+mlHWtE0h/Sn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["For eNE recognition we need a map of a form {PMID:publishing year}, with an entry for every PubMed paper.\n","\n"],"metadata":{"id":"d74OJneZlkyW"}},{"cell_type":"code","source":["#mount google drive to use data\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VMmfso4QpEa1","executionInfo":{"status":"ok","timestamp":1660766488403,"user_tz":-120,"elapsed":22106,"user":{"displayName":"Victoria Dimanova","userId":"07172063658264964881"}},"outputId":"fa248a16-aa82-4bdd-e75c-2e3c02f170ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tv6jy5fklfBJ"},"outputs":[],"source":["import re\n","import json\n","\n","def create_paper_year_map(pubmed_results_file):\n","  \"\"\"\n","  create a dictionary that contains mapping of PMIDs of PubMed \n","  articles to its publishing year\n","  \"\"\"\n","  paper_year_map = {}\n","  year_regex = r\"[0-9]{4,4} [A-Z,a-z]{3,3} [0-9]{1,2};\"\n","  short_year_regex =r\"[0-9]{4,4} [A-Z,a-z]{3,3};\"\n","  exception_year_regex = r\"[0-9]{4,4} [A-Z,a-z]{3,3}-\"\n","  epub_regex = r\"Epub [0-9]{4,4} \"\n","  pmid_regex = r\"PMID:[ ]{0,1}[0-9]+\"\n","  \n","  with open(pubmed_results_file, encoding=\"utf8\") as f:    \n","    current_text = \"\"   \n","    for line in f:  \n","      clean_line = line.replace(\"\\n\", \" \")     \n","      current_text += clean_line      \n","      if clean_line == \" \":  \n","         print(\"---\") \n","         pmid_match = re.search(pmid_regex, current_text)  \n","         if pmid_match: \n","           pmid_clean = pmid_match.group().replace(\"PMID: \", \"\").replace(\";\", \"\")\n","           epub_match = re.search(epub_regex, current_text)\n","           if epub_match:\n","             clean_epub = epub_match.group().split(\" \")[1]\n","             paper_year_map[pmid_clean] = clean_epub\n","             current_text = \"\" \n","             print(pmid_clean)\n","             print(\"epub \" + clean_epub)\n","             continue\n","           else:\n","             year_match = re.search(year_regex, current_text)\n","             if year_match:\n","               year_clean = year_match.group().split(\" \")[0]\n","               paper_year_map[pmid_clean] = year_clean\n","               current_text = \"\"  \n","               print(pmid_clean)\n","               print(\"year \" + year_clean)\n","               continue\n","             else:\n","               short_year_match = re.search(short_year_regex, current_text)\n","               if short_year_match:\n","                 clean_short_year = short_year_match.group().split(\" \")[0]\n","                 paper_year_map[pmid_clean] = year_clean\n","                 current_text = \"\"   \n","                 print(pmid_clean)\n","                 print(\"short_year \" + clean_short_year)\n","               else:\n","                 exception_year_match = re.search(short_year_regex, current_text)\n","                 if exception_year_match:\n","                   exception_short_year = exception_year_match.group().split(\" \")[0]\n","                   current_text = \"\"\n","                   print(pmid_clean)\n","                   print(\"exception_year \" + exception_short_year)\n","                   current_text = \"\"\n","         else:\n","          print(\"PMID NOT found\")   \n","          current_text = \"\"\n","    return paper_year_map\n","\n","\n","def write_result(result_dict, file_name):\n","  \"\"\"\n","  write extracted pmid and years in the file\n","  \"\"\" \n","  with open(file_name, \"w\", encoding=\"utf8\") as f:\n","    f.write(json.dumps(result_dict))    \n","\n","\n","\n","\n","results = \"/content/drive/MyDrive/TextcorpusCreation/summary-geneexpres-set.txt\"    \n","pmid_year_map = \"/content/drive/MyDrive/TextcorpusCreation/pmid_year_map.json\"  \n","pmid_year = create_paper_year_map(results)\n","write_result(pmid_year, pmid_year_map)\n"]}]}